{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing to make atomic event - similarity map\n",
    "use cosine similarity score..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import join\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "import copy\n",
    "from itertools import combinations\n",
    "%matplotlib inline\n",
    "\n",
    "video_info_path = '/mnt/GitHub/G_TAD_customizing/data/thumos_annotations/'\n",
    "video_ft_path = '/mnt/GitHub/G_TAD_customizing/data/thumos_feature/TSN_pretrain_avepool_allfrms_hdf5/'\n",
    "# annotations path\n",
    "valid_path = os.path.join(video_info_path, 'val_Annotation.csv')\n",
    "test_path = os.path.join(video_info_path, 'test_Annotation.csv')\n",
    "\n",
    "# features path\n",
    "valid_rgb = os.path.join(video_ft_path, 'rgb_val.h5')\n",
    "valid_flow = os.path.join(video_ft_path, 'flow_val.h5')\n",
    "test_rgb = os.path.join(video_ft_path, 'rgb_test.h5')\n",
    "test_flow = os.path.join(video_ft_path, 'flow_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bunch of functions\n",
    "# cosine similarity\n",
    "def cos_sim_mat(test_feat):\n",
    "    \"\"\"\n",
    "    returns cosine similarity matrix of given vectors.\n",
    "    \"\"\"\n",
    "    dist_out = 1-pairwise_distances(test_feat, metric=\"cosine\")\n",
    "    return dist_out\n",
    "\n",
    "\n",
    "# 1D pca function\n",
    "def pca1(input_mat):\n",
    "    \"\"\"\n",
    "    does 1D-PCA on given vectors.\n",
    "    the vectors shoulbe be in shape of (num_samples, num_features)\n",
    "    returns:\n",
    "        - 1D-PCA result of given vectors.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=1,whiten=True)\n",
    "    pca_ed = np.squeeze(pca.fit_transform(input_mat))\n",
    "    return pca_ed\n",
    "\n",
    "# diagonal matrix function\n",
    "def get_diagonal_matrix(ref_mat,thickness=1):\n",
    "    \"\"\"\n",
    "    makes diagonal identity matrix of custom thickness\n",
    "    args:\n",
    "        - ref_mat: reference square matrix. the output will be the same shape with ref_mat.\n",
    "        - thickness: thickness of diagonal matrix\n",
    "    returns:\n",
    "        - identity matrix of shape ref_mat.shape, thickness of \"thickness\" arg.\n",
    "    \"\"\"\n",
    "    diag_mat = np.identity(ref_mat.shape[0])\n",
    "    for i in range(1,thickness):\n",
    "        id_mat = np.identity(ref_mat.shape[0])\n",
    "        right_mat = np.concatenate([id_mat[i:],np.zeros([i,*id_mat.shape[1:]])])\n",
    "        left_mat = np.concatenate([np.zeros([i,*id_mat.shape[1:]]),id_mat[:-i]])\n",
    "        diag_mat += right_mat\n",
    "        diag_mat += left_mat\n",
    "    return diag_mat\n",
    "\n",
    "def center_cleansing(mat,clean_thickness=2,avg_length=2):\n",
    "    \"\"\"\n",
    "    make diagonal elements of given matrix smooth, \n",
    "    by replacing their values with weighted-mean(adjcent elements)\n",
    "    (not used now)\n",
    "    \"\"\"\n",
    "    center_mask = get_diagonal_matrix(mat,clean_thickness)\n",
    "    avg_mask = get_diagonal_matrix(mat,clean_thickness+avg_length)\n",
    "    avg_mask = avg_mask - center_mask\n",
    "    avg_sums =  np.mean(mat * avg_mask,axis=1)\n",
    "    avg_cnts = np.mean(avg_mask > 1e-5,axis=1)\n",
    "    avg_values = avg_sums / avg_cnts\n",
    "    center_values = center_mask * np.expand_dims(avg_values,axis=1)\n",
    "    new_mat = np.array(mat)\n",
    "    new_mat[center_mask > 1e-5] = 0.0\n",
    "    new_mat += center_values\n",
    "    return new_mat\n",
    "\n",
    "def mat_thresh(mat):\n",
    "    \"\"\"\n",
    "    adaptively threshold given matrix.\n",
    "    The threshold value is determined by\n",
    "    (mean(mat) + 1.0) / 2\n",
    "    \"\"\"\n",
    "    avg_val = np.mean(mat)\n",
    "    avg_thresh = (avg_val + 1) / 2\n",
    "    new_mat = np.array(mat)\n",
    "    new_mat[mat>avg_thresh] = avg_thresh\n",
    "    return new_mat\n",
    "\n",
    "def kmeans_clustering(mat,time_scale=1,n_clusters=3):\n",
    "    \"\"\"\n",
    "    Does k-means clustering, but attaches relative timestamp as feature of input vector to encourage the resulting classes time-related.\n",
    "    the input vectors shoulbe be in shape of (num_samples, num_features).\n",
    "    args:\n",
    "        - mat: input vectors. shoulbe be in shape of (num_samples, num_features).\n",
    "        - time_scale: the weight applied to time feature.\n",
    "        - n_clusters: number of k-means clusters\n",
    "    \"\"\"\n",
    "    mat_length = mat.shape[0]\n",
    "    timestamps = np.expand_dims(np.linspace(start=0,stop=time_scale,num=mat_length),axis=1)\n",
    "    mat_with_timestamps = np.concatenate([mat,timestamps],axis=1)\n",
    "    kmeans = KMeans(n_clusters=n_clusters,tol=1e-5,max_iter=400, random_state=1234)\n",
    "    kmeans_classes = kmeans.fit_predict(mat_with_timestamps)\n",
    "    kmeans_centers = kmeans.cluster_centers_\n",
    "    kmeans_centers = np.array(kmeans_centers)\n",
    "    return kmeans_classes, kmeans_centers\n",
    "\n",
    "def flatten_class(class_sequence,window_size=5  ):\n",
    "    \"\"\"\n",
    "    tries to remove sudden incorrect occurances(noisy labels) by smoothing out the class sequence.\n",
    "    does sliding window, that selects most frequent element in the window.\n",
    "    args:\n",
    "        - class_sequence: the sequence of k-means classes. this is an output of [kmens_clustering] function.\n",
    "        - window_size: sliding window size. should be odd.\n",
    "    \"\"\"\n",
    "    radius = window_size // 2\n",
    "    flattened_sequence = np.array(class_sequence)\n",
    "    for center in range(len(class_sequence)):\n",
    "        close_elements = class_sequence[max(0,center-radius):min(center+radius,len(class_sequence))]\n",
    "        most_frequent_class = np.argmax(np.bincount(close_elements))\n",
    "        flattened_sequence[center] = most_frequent_class\n",
    "    return flattened_sequence\n",
    "\n",
    "def merge_classes(class_sequence,kmeans_centers,thresh=0.996):\n",
    "    \"\"\"\n",
    "    given k-means results (class sequence and cluster centers), \n",
    "    merge classes that have too close centers.\n",
    "    args:\n",
    "        - class_sequence: the sequence of k-means classes. I recommand using the output of [flatten_class] fuction\n",
    "        - kmeans_centers: the center vector k-means clustering. i.e. an output of [kmeans_clustering] function.\n",
    "        - thresh: merging threshold of class center similarity (metric: cosine similarity)\n",
    "    returns:\n",
    "        - class sequence with merged classes\n",
    "    \"\"\"\n",
    "    num_classes = kmeans_centers.shape[0]\n",
    "    class_counts = np.bincount(class_sequence)\n",
    "    class_similarity = cos_sim_mat(kmeans_centers) - np.identity(num_classes)\n",
    "    for i in range(num_classes):\n",
    "        for j in range(i+1,num_classes):\n",
    "            if class_similarity[i,j] > thresh:\n",
    "                if class_counts[i] >= class_counts[j]:\n",
    "                    class_sequence[class_sequence == j] = i\n",
    "                else:\n",
    "                    class_sequence[class_sequence == i] = j\n",
    "    return class_sequence\n",
    "\n",
    "def get_transition_sites(class_sequence):\n",
    "    \"\"\"\n",
    "    given class sequcne, finds transition sites.\n",
    "    args:\n",
    "        - class_sequence: the sequence of k-means classes. I recommand using the output of [merge_classes] function\n",
    "    \"\"\"\n",
    "    current_class = class_sequence[0]\n",
    "    transition_sites = []\n",
    "    transition_sites.append(0)\n",
    "    for i,val in enumerate(class_sequence):\n",
    "        if val != current_class:\n",
    "            current_class = val\n",
    "            transition_sites.append(i)\n",
    "    transition_sites.append(len(class_sequence))\n",
    "    return transition_sites\n",
    "\n",
    "def remove_short_transition(transition_sites,thresh=120):\n",
    "    \"\"\"\n",
    "    removes transitions that are too close from others.\n",
    "    \"\"\"\n",
    "    if len(transition_sites) < 4:\n",
    "        return transition_sites\n",
    "    for i in range(len(transition_sites) - 1):\n",
    "        forward_difference = transition_sites[i+1] - transition_sites[i]\n",
    "        if forward_difference <= thresh:\n",
    "            transition_sites[i] = transition_sites[-1]\n",
    "    transition_sites.append(0)\n",
    "    transition_sites = list(set(transition_sites))\n",
    "    transition_sites = sorted(transition_sites)\n",
    "    return transition_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df_valid = pd.read_csv(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_name_list = sorted(list(set(anno_df_valid.video.values[:])))\n",
    "len(video_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in raw feature files extracted by TSN\n",
    "flow_val_ft = h5py.File(valid_flow, 'r')\n",
    "rgb_val_ft = h5py.File(valid_rgb, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "videoname >>>  video_validation_0000051\n",
      "(5090, 1024) (5090, 1024)\n",
      "(5090, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 14\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000052\n",
      "(4990, 1024) (4990, 1024)\n",
      "(4990, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:17,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 11\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000053\n",
      "(5915, 1024) (5915, 1024)\n",
      "(5915, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:31,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 25\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000054\n",
      "(4049, 1024) (4049, 1024)\n",
      "(4049, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:37,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 8\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000055\n",
      "(4882, 1024) (4882, 1024)\n",
      "(4882, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:46,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 8\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000056\n",
      "(4128, 1024) (4128, 1024)\n",
      "(4128, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:53,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 8\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000057\n",
      "(6830, 1024) (6830, 1024)\n",
      "(6830, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [01:12, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 12\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000058\n",
      "(3957, 1024) (3957, 1024)\n",
      "(3957, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:16,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 13\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000059\n",
      "(6863, 1024) (6863, 1024)\n",
      "(6863, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [01:29, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 24\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000060\n",
      "(5610, 1024) (5610, 1024)\n",
      "(5610, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:40, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 10\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000151\n",
      "(1003, 1024) (1003, 1024)\n",
      "(1003, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [01:40,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 5\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000152\n",
      "(4971, 1024) (4971, 1024)\n",
      "(4971, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [01:52,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 14\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000153\n",
      "(5139, 1024) (5139, 1024)\n",
      "(5139, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [02:04,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 13\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000154\n",
      "(1572, 1024) (1572, 1024)\n",
      "(1572, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [02:05,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 5\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000155\n",
      "(2262, 1024) (2262, 1024)\n",
      "(2262, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [02:07,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 7\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000156\n",
      "(7121, 1024) (7121, 1024)\n",
      "(7121, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [02:23,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 25\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000157\n",
      "(1508, 1024) (1508, 1024)\n",
      "(1508, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [02:24,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 5\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000158\n",
      "(9196, 1024) (9196, 1024)\n",
      "(9196, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [02:49, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 24\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000159\n",
      "(13357, 1024) (13357, 1024)\n",
      "(13357, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [04:28, 38.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 37\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000160\n",
      "(12237, 1024) (12237, 1024)\n",
      "(12237, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [05:39, 47.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 33\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000161\n",
      "(1851, 1024) (1851, 1024)\n",
      "(1851, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [05:40, 33.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 5\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000162\n",
      "(5940, 1024) (5940, 1024)\n",
      "(5940, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [05:54, 27.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 18\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000163\n",
      "(7015, 1024) (7015, 1024)\n",
      "(7015, 2048)\n",
      "clustering start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [06:13, 25.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary count 19\n",
      "transition boundary info saved\n",
      "videoname >>>  video_validation_0000164\n",
      "(5200, 1024) (5200, 1024)\n",
      "(5200, 2048)\n",
      "clustering start\n"
     ]
    }
   ],
   "source": [
    "# vid_sim = []\n",
    "\n",
    "clustering_trials = 6\n",
    "transition_boundary_info = {}\n",
    "\n",
    "for cnt, i in tqdm(enumerate(video_name_list)):\n",
    "    print('videoname >>> ', i)\n",
    "    # get feature for each video\n",
    "    tmp = np.array(flow_val_ft[i])\n",
    "    tmp2 = np.array(rgb_val_ft[i])\n",
    "    mat = np.concatenate([tmp, tmp2], axis=1)\n",
    "    \n",
    "    print(tmp.shape, tmp2.shape)\n",
    "    print(mat.shape)\n",
    "    # get similarity matrix\n",
    "    sim_mat = mat @ (mat.T)\n",
    "    \n",
    "    # in order to divide to norm of each vector\n",
    "    tmp_norm = np.linalg.norm(mat, axis=1)\n",
    "    tmp_norm = tmp_norm.reshape(-1, 1)\n",
    "    \n",
    "    # calculate norm mult norm\n",
    "    norm = tmp_norm @ tmp_norm.T\n",
    "    \n",
    "    # calculate final cosine similarity\n",
    "    similarity = np.divide(sim_mat, norm)\n",
    "    # vid_sim.append(similarity)\n",
    "    # print(similarity)\n",
    "    # plt.imshow(similarity)\n",
    "    sim_mat = similarity\n",
    "    another_sim_mat = mat_thresh(sim_mat)\n",
    "    # another_sim_mat = sim_mat # just use it directly\n",
    "    max_points = 0\n",
    "    top_transition_sites = None\n",
    "    print('clustering start')\n",
    "    for j in range(clustering_trials):\n",
    "        # print('clustering trials : ', j)\n",
    "        kmeans_classes, kmeans_centers = kmeans_clustering(another_sim_mat)\n",
    "        kmeans_classes = merge_classes(kmeans_classes,kmeans_centers)\n",
    "        kmeans_classes = flatten_class(kmeans_classes)\n",
    "        transition_sites = get_transition_sites(kmeans_classes)\n",
    "        transition_sites = remove_short_transition(transition_sites)\n",
    "        if len(transition_sites) > max_points:\n",
    "            max_points = len(transition_sites)\n",
    "            top_transition_sites = transition_sites\n",
    "    # draw sim mat\n",
    "    # fig = plt.figure(num=3,figsize=(9,3))\n",
    "    # # draw thresholded version\n",
    "    # fig.add_subplot(1,3,1)\n",
    "    # plt.imshow(another_sim_mat)\n",
    "    # for t in top_transition_sites:\n",
    "    #     plt.axvline(t,color='k')\n",
    "    # plt.title(\"{}/atomic_sim_mat\".format(i))\n",
    "    print('boundary count', len(top_transition_sites))\n",
    "    # for t in top_transition_sites:\n",
    "    #     plt.axvline(t,color='k')\n",
    "    #     # print(t)\n",
    "    transition_boundary_info[i] = {\"top_transition_sites\":top_transition_sites, \"frames\":sim_mat.shape[0]}\n",
    "    print('transition boundary info saved\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temporal_info.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(transition_boundary_info, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a17234fb54da4afdb7e62dfc1789cf2c166134a73f23c79d94b6e755d1148c2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('gtad': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
